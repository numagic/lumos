{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/numagic/lumos/blob/update_colab/tutorials/colab/Laptime_simulation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwyQYIZbVKFh"
      },
      "source": [
        "# Introduction\n",
        "Usually it is recommended to use lumos with the docker image it provides. But we can also run `lumos` with conda environment.\n",
        "\n",
        "Google Colab provides free GPU and TPU VMs that one could use with jupyter notebook style UI, and this is what we're going to use.\n",
        "\n",
        "To set up the environment, we'll:\n",
        "1) install conda on google colab using `condacolab`\n",
        "2) clone the `lumos` git repo, and setup the conda environment (this will be replaced by pip install in the future)\n",
        "3) run laptime simulation example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBzkeuwE5oUV"
      },
      "source": [
        "# Install Conda on Google Colab\n",
        "\n",
        "<!-- By Jaime Rodr√≠guez-Guerra <@jaimergp>. Last modified 2021.08.04 -->\n",
        "\n",
        "`condacolab` simplifies the setup as much as possible, but there are some gotchas.\n",
        "\n",
        "**‚ö†Ô∏è Read this before continuing!**\n",
        "\n",
        "* The `condacolab` commands need to be run the first Code cell!\n",
        "* Once you run `condacolab.install()`, the Python kernel will be restarted. This is **normal and expected**. After that, you can continue running the cells below like normal.\n",
        "* Do not use the `Run all` option. Run the `condacolab` cell _individually_ and wait for the kernel to restart. **Only then**, you can run all cells if you want.\n",
        "* You can only use the `base` environment. Do not try to create new ones; instead update `base` with either:\n",
        "  * `conda install <packages>`\n",
        "  * `conda env update -n base -f environment.yml`\n",
        "* If you want to use GPUs, make sure you are using such an instance before starting!\n",
        "* If you get an error, please raise an issue [here](https://github.com/jaimergp/condacolab/issues)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAZ11nESX6qt",
        "outputId": "65833c45-9f6a-4a17-dac3-0cd6dc43445d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚è¨ Downloading https://github.com/jaimergp/miniforge/releases/latest/download/Mambaforge-colab-Linux-x86_64.sh...\n",
            "üì¶ Installing...\n",
            "üìå Adjusting configuration...\n",
            "ü©π Patching environment...\n",
            "‚è≤ Done in 0:00:21\n",
            "üîÅ Restarting kernel...\n"
          ]
        }
      ],
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRDyL3hPYAOx",
        "outputId": "7c658505-b5f6-4731-b7aa-82d849f7df9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ú®üç∞‚ú® Everything looks OK!\n"
          ]
        }
      ],
      "source": [
        "import condacolab\n",
        "condacolab.check()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5y2J1e9SFldl",
        "outputId": "c63410bd-7e46-4f16-c709-0e468afdfc70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Mon_Oct_12_20:09:46_PDT_2020\n",
            "Cuda compilation tools, release 11.1, V11.1.105\n",
            "Build cuda_11.1.TC455_06.29190527_0\n",
            "Wed May 11 19:02:38 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P8    11W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# Make sure cuda is available\n",
        "!nvcc --version\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKLRjjAcVzQ0"
      },
      "source": [
        "# Setup `lumos` environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37snqz80GjQ0",
        "outputId": "70ed163a-8d6d-48cc-bafd-470746a74f4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'lumos'...\n",
            "remote: Enumerating objects: 426, done.\u001b[K\n",
            "remote: Counting objects: 100% (154/154), done.\u001b[K\n",
            "remote: Compressing objects: 100% (118/118), done.\u001b[K\n",
            "remote: Total 426 (delta 67), reused 48 (delta 32), pack-reused 272\u001b[K\n",
            "Receiving objects: 100% (426/426), 706.20 KiB | 6.60 MiB/s, done.\n",
            "Resolving deltas: 100% (128/128), done.\n",
            "/content/lumos\n",
            "data\t\t\tenvironment.yml  lumos\t\t   setup.py\n",
            "docker\t\t\texamples\t pyproject.toml    tests\n",
            "docker-compose.gpu.yml\timgs\t\t README.md\t   tutorials\n",
            "docker-compose.yml\tLICENSE\t\t regression_tests\n"
          ]
        }
      ],
      "source": [
        "# Clone repo and enter the right path\n",
        "!git clone https://github.com/numagic/lumos.git\n",
        "%cd lumos\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KbliymBeS_Nf",
        "outputId": "14077dbf-4d43-4e07-90e8-c63877ce7850"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Solving environment: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - cyipopt\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    ampl-mp-3.1.0              |    h2cc385e_1006         1.1 MB  conda-forge\n",
            "    ca-certificates-2021.10.8  |       ha878542_0         139 KB  conda-forge\n",
            "    certifi-2021.10.8          |   py37h89c1867_2         145 KB  conda-forge\n",
            "    conda-4.12.0               |   py37h89c1867_0         1.0 MB  conda-forge\n",
            "    cyipopt-1.1.0              |   py37h4f1d67c_1         144 KB  conda-forge\n",
            "    future-0.18.2              |   py37h89c1867_5         713 KB  conda-forge\n",
            "    ipopt-3.14.6               |       h630875f_0         1.1 MB  conda-forge\n",
            "    libblas-3.9.0              |14_linux64_openblas          12 KB  conda-forge\n",
            "    libcblas-3.9.0             |14_linux64_openblas          12 KB  conda-forge\n",
            "    libgcc-ng-11.2.0           |      h1d223b6_16         902 KB  conda-forge\n",
            "    libgfortran-ng-11.2.0      |      h69a702a_16          23 KB  conda-forge\n",
            "    libgfortran5-11.2.0        |      h5c6108e_16         1.7 MB  conda-forge\n",
            "    libgomp-11.2.0             |      h1d223b6_16         428 KB  conda-forge\n",
            "    liblapack-3.9.0            |14_linux64_openblas          12 KB  conda-forge\n",
            "    libopenblas-0.3.20         |pthreads_h78a6416_0        10.1 MB  conda-forge\n",
            "    libstdcxx-ng-11.2.0        |      he4da1e4_16         4.2 MB  conda-forge\n",
            "    metis-5.1.0                |    h58526e2_1006         4.1 MB  conda-forge\n",
            "    mumps-include-5.2.1        |      ha770c72_11          23 KB  conda-forge\n",
            "    mumps-seq-5.2.1            |      h2104b81_11         3.3 MB  conda-forge\n",
            "    numpy-1.21.6               |   py37h976b520_0         6.1 MB  conda-forge\n",
            "    openssl-1.1.1o             |       h166bdaf_0         2.1 MB  conda-forge\n",
            "    python_abi-3.7             |          2_cp37m           4 KB  conda-forge\n",
            "    scotch-6.0.9               |       h3858553_1         1.3 MB  conda-forge\n",
            "    unixodbc-2.3.10            |       h583eb01_0         296 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        38.9 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  ampl-mp            conda-forge/linux-64::ampl-mp-3.1.0-h2cc385e_1006\n",
            "  cyipopt            conda-forge/linux-64::cyipopt-1.1.0-py37h4f1d67c_1\n",
            "  future             conda-forge/linux-64::future-0.18.2-py37h89c1867_5\n",
            "  ipopt              conda-forge/linux-64::ipopt-3.14.6-h630875f_0\n",
            "  libblas            conda-forge/linux-64::libblas-3.9.0-14_linux64_openblas\n",
            "  libcblas           conda-forge/linux-64::libcblas-3.9.0-14_linux64_openblas\n",
            "  libgfortran-ng     conda-forge/linux-64::libgfortran-ng-11.2.0-h69a702a_16\n",
            "  libgfortran5       conda-forge/linux-64::libgfortran5-11.2.0-h5c6108e_16\n",
            "  liblapack          conda-forge/linux-64::liblapack-3.9.0-14_linux64_openblas\n",
            "  libopenblas        conda-forge/linux-64::libopenblas-0.3.20-pthreads_h78a6416_0\n",
            "  metis              conda-forge/linux-64::metis-5.1.0-h58526e2_1006\n",
            "  mumps-include      conda-forge/linux-64::mumps-include-5.2.1-ha770c72_11\n",
            "  mumps-seq          conda-forge/linux-64::mumps-seq-5.2.1-h2104b81_11\n",
            "  numpy              conda-forge/linux-64::numpy-1.21.6-py37h976b520_0\n",
            "  scotch             conda-forge/linux-64::scotch-6.0.9-h3858553_1\n",
            "  unixodbc           conda-forge/linux-64::unixodbc-2.3.10-h583eb01_0\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  ca-certificates                      2020.12.5-ha878542_0 --> 2021.10.8-ha878542_0\n",
            "  certifi                          2020.12.5-py37h89c1867_1 --> 2021.10.8-py37h89c1867_2\n",
            "  conda                                4.9.2-py37h89c1867_0 --> 4.12.0-py37h89c1867_0\n",
            "  libgcc-ng                               9.3.0-h2828fa1_18 --> 11.2.0-h1d223b6_16\n",
            "  libgomp                                 9.3.0-h2828fa1_18 --> 11.2.0-h1d223b6_16\n",
            "  libstdcxx-ng                            9.3.0-h6de172a_18 --> 11.2.0-he4da1e4_16\n",
            "  openssl                                 1.1.1j-h7f98852_0 --> 1.1.1o-h166bdaf_0\n",
            "  python_abi                                    3.7-1_cp37m --> 3.7-2_cp37m\n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "future-0.18.2        | 713 KB    | : 100% 1.0/1 [00:00<00:00,  3.45it/s]\n",
            "ca-certificates-2021 | 139 KB    | : 100% 1.0/1 [00:00<00:00, 18.96it/s]\n",
            "mumps-include-5.2.1  | 23 KB     | : 100% 1.0/1 [00:00<00:00, 17.71it/s]\n",
            "ipopt-3.14.6         | 1.1 MB    | : 100% 1.0/1 [00:00<00:00,  3.83it/s]\n",
            "unixodbc-2.3.10      | 296 KB    | : 100% 1.0/1 [00:00<00:00, 12.37it/s]\n",
            "liblapack-3.9.0      | 12 KB     | : 100% 1.0/1 [00:00<00:00, 24.78it/s]\n",
            "libcblas-3.9.0       | 12 KB     | : 100% 1.0/1 [00:00<00:00, 19.03it/s]\n",
            "mumps-seq-5.2.1      | 3.3 MB    | : 100% 1.0/1 [00:00<00:00,  1.97it/s]\n",
            "openssl-1.1.1o       | 2.1 MB    | : 100% 1.0/1 [00:00<00:00,  3.06it/s]\n",
            "python_abi-3.7       | 4 KB      | : 100% 1.0/1 [00:00<00:00, 11.99it/s]\n",
            "libstdcxx-ng-11.2.0  | 4.2 MB    | : 100% 1.0/1 [00:00<00:00,  1.61it/s]\n",
            "libgfortran-ng-11.2. | 23 KB     | : 100% 1.0/1 [00:00<00:00, 21.47it/s]\n",
            "scotch-6.0.9         | 1.3 MB    | : 100% 1.0/1 [00:00<00:00,  2.95it/s]\n",
            "conda-4.12.0         | 1.0 MB    | : 100% 1.0/1 [00:00<00:00,  4.36it/s]\n",
            "metis-5.1.0          | 4.1 MB    | : 100% 1.0/1 [00:00<00:00,  1.56it/s]\n",
            "certifi-2021.10.8    | 145 KB    | : 100% 1.0/1 [00:00<00:00, 14.57it/s]\n",
            "libgfortran5-11.2.0  | 1.7 MB    | : 100% 1.0/1 [00:00<00:00,  3.22it/s]\n",
            "libgcc-ng-11.2.0     | 902 KB    | : 100% 1.0/1 [00:00<00:00,  5.17it/s]\n",
            "numpy-1.21.6         | 6.1 MB    | : 100% 1.0/1 [00:01<00:00,  1.29s/it]               \n",
            "cyipopt-1.1.0        | 144 KB    | : 100% 1.0/1 [00:00<00:00,  9.68it/s]\n",
            "libgomp-11.2.0       | 428 KB    | : 100% 1.0/1 [00:00<00:00,  9.31it/s]\n",
            "libopenblas-0.3.20   | 10.1 MB   | : 100% 1.0/1 [00:01<00:00,  1.65s/it]\n",
            "libblas-3.9.0        | 12 KB     | : 100% 1.0/1 [00:00<00:00, 21.85it/s]\n",
            "ampl-mp-3.1.0        | 1.1 MB    | : 100% 1.0/1 [00:00<00:00,  4.72it/s]\n",
            "Preparing transaction: | \b\bdone\n",
            "Verifying transaction: - \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Executing transaction: \\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Collecting casadi\n",
            "  Downloading casadi-3.5.5-cp37-none-manylinux1_x86_64.whl (34.2 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 34.2 MB 46 kB/s \n",
            "\u001b[?25hCollecting pyarrow\n",
            "  Downloading pyarrow-8.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.3 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29.3 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting pandas\n",
            "  Downloading pandas-1.3.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11.3 MB 42.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/site-packages (from pandas) (1.21.6)\n",
            "Collecting python-dateutil>=2.7.3\n",
            "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 247 kB 67.5 MB/s \n",
            "\u001b[?25hCollecting pytz>=2017.3\n",
            "  Downloading pytz-2022.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 503 kB 69.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Installing collected packages: pytz, python-dateutil, pyarrow, pandas, casadi\n",
            "Successfully installed casadi-3.5.5 pandas-1.3.5 pyarrow-8.0.0 python-dateutil-2.8.2 pytz-2022.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "dateutil"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://storage.googleapis.com/jax-releases/jax_releases.html\n",
            "Collecting jax[cuda11_cudnn82]\n",
            "  Downloading https://storage.googleapis.com/jax-releases/jax/jax-0.3.10.tar.gz (939 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 939 kB 7.0 MB/s \n",
            "\u001b[?25hCollecting absl-py\n",
            "  Downloading absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126 kB 4.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.7/site-packages (from jax[cuda11_cudnn82]) (1.21.6)\n",
            "Collecting opt_einsum\n",
            "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 65 kB 4.8 MB/s \n",
            "\u001b[?25hCollecting scipy>=1.2.1\n",
            "  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 38.1 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting typing_extensions\n",
            "  Downloading typing_extensions-4.2.0-py3-none-any.whl (24 kB)\n",
            "Collecting jaxlib==0.3.10+cuda11.cudnn82\n",
            "  Downloading https://storage.googleapis.com/jax-releases/cuda11/jaxlib-0.3.10%2Bcuda11.cudnn82-cp37-none-manylinux2014_x86_64.whl (128.0 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128.0 MB 25 kB/s \n",
            "\u001b[?25hCollecting flatbuffers<3.0,>=1.12\n",
            "  Downloading flatbuffers-2.0-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/site-packages (from absl-py->jax[cuda11_cudnn82]) (1.15.0)\n",
            "Building wheels for collected packages: jax\n",
            "  Building wheel for jax (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jax: filename=jax-0.3.10-py3-none-any.whl size=1088071 sha256=0a9cc5b951fc509ade99464179cdc2945246388dc406568a9c7dc2570c4f0ade\n",
            "  Stored in directory: /root/.cache/pip/wheels/b6/49/8a/c5c6fe6cbf20826b70f32ca35725228dc252aacc2ba242e190\n",
            "Successfully built jax\n",
            "Installing collected packages: typing-extensions, scipy, opt-einsum, flatbuffers, absl-py, jaxlib, jax\n",
            "Successfully installed absl-py-1.0.0 flatbuffers-2.0 jax-0.3.10 jaxlib-0.3.10+cuda11.cudnn82 opt-einsum-3.3.0 scipy-1.7.3 typing-extensions-4.2.0\n",
            "Collecting numagic-lumos==0.0.2rc2\n",
            "  Downloading numagic_lumos-0.0.2rc2-py3-none-any.whl (105 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 105 kB 4.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: numagic-lumos\n",
            "Successfully installed numagic-lumos-0.0.2rc2\n"
          ]
        }
      ],
      "source": [
        "# Colab by default uses python 3.7, which we can't change. Condacolab also only\n",
        "# supports the base env, which we update.\n",
        "# It may take 4-5 minutes to set up the conda environment, particularly\n",
        "# with setting up the cuda toolkit for the GPU.\n",
        "# !conda env update -n base -f environment.yml\n",
        "\n",
        "# Or... we could direclty install them which seems faster than asking conda to\n",
        "# solve for the environment. So we'll take this to make the colab experience\n",
        "# better.\n",
        "# TODO: make dependency automatic -> this would require conda as there are\n",
        "# non-python dependencies\n",
        "!conda install -c conda-forge cyipopt\n",
        "!pip install casadi pyarrow pandas\n",
        "# Install the GPU version of jax to use GPU (need correct cuda version)\n",
        "!pip install jax[cuda11_cudnn82] -f https://storage.googleapis.com/jax-releases/jax_releases.html\n",
        "# install lumos\n",
        "!pip install numagic-lumos==0.0.2rc2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rtT5PiHOYy5",
        "outputId": "b6f123b1-3e1a-4073-9a74-cbdedfc7a6ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GpuDevice(id=0, process_index=0)]\n"
          ]
        }
      ],
      "source": [
        "# test jax on GPU, if you see a spike in the GPU ram used -> yes, you're using GPU\n",
        "# If you see warnings about GPU not found, then either the VM connected has no\n",
        "# GPU or the support packages are not installed correctly\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "a = np.random.randn(100, 100)\n",
        "b = np.random.randn(100, 100)\n",
        "c = jnp.dot(a, b)\n",
        "\n",
        "\n",
        "print(jax.devices())\n",
        "del a, b, c"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QiYXcrNuV5jt"
      },
      "source": [
        "# Run laptime simulation example\n",
        "\n",
        "Note that unfortunately colab does not show the stdout printed to the terminal, therefore the user must use the command tabs: 'Runtime' -> 'View runtime logs' to see the stdout outputs, such as those from IPOPT."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVrfw3Ir0gwL",
        "outputId": "9697e370-f079-4823-95a6-82d5437f0f5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n",
            "DEBUG:lumos.models.tires.utils:FILE_TYPE is not a numeric value and is discarded.\n",
            "DEBUG:lumos.models.tires.utils:FILE_FORMAT is not a numeric value and is discarded.\n",
            "DEBUG:lumos.models.tires.utils:LENGTH is not a numeric value and is discarded.\n",
            "DEBUG:lumos.models.tires.utils:FORCE is not a numeric value and is discarded.\n",
            "DEBUG:lumos.models.tires.utils:ANGLE is not a numeric value and is discarded.\n",
            "DEBUG:lumos.models.tires.utils:MASS is not a numeric value and is discarded.\n",
            "DEBUG:lumos.models.tires.utils:TIME is not a numeric value and is discarded.\n",
            "DEBUG:lumos.models.tires.utils:TYRESIDE is not a numeric value and is discarded.\n",
            "WARNING:lumos.simulations.laptime_simulation:states.time must be non-cyclic, automatically adding it to the list.\n",
            "WARNING:lumos.simulations.laptime_simulation:inputs.track_heading must be non-cyclic, automatically adding it to the list.\n",
            "INFO:lumos.models.tracks:left distance violation: 0\n",
            "INFO:lumos.models.tracks:right distance violation: 0\n",
            "WARNING:absl:Finished tracing + transforming apply_and_forward for jit in 0.7687845230102539 sec\n",
            "WARNING:absl:Compiling apply_and_forward (140345740290672) for 95 args.\n",
            "WARNING:absl:Finished XLA compilation of apply_and_forward in 1.1458117961883545 sec\n",
            "INFO:lumos.optimal_control.scaled_mesh_ocp:Triggering jax JIT\n",
            "INFO:lumos.optimal_control.nlp:time.objective: 0.000032\n",
            "INFO:lumos.optimal_control.nlp:time.gradient: 0.000249\n",
            "INFO:lumos.optimal_control.nlp:time.hessian: 0.000008\n",
            "INFO:lumos.optimal_control.nlp:inputs_penalty.objective: 0.000692\n",
            "INFO:lumos.optimal_control.nlp:inputs_penalty.gradient: 0.006202\n",
            "INFO:lumos.optimal_control.nlp:inputs_penalty.hessian: 0.000246\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting the first solve!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Finished tracing + transforming _apply_and_flat_implicit for jit in 0.7326595783233643 sec\n",
            "WARNING:absl:Compiling _apply_and_flat_implicit (140345736412816) for 94 args.\n",
            "WARNING:absl:Finished XLA compilation of _apply_and_flat_implicit in 1.0479285717010498 sec\n",
            "INFO:lumos.optimal_control.nlp:model_algebra.constraints: 2.246174\n",
            "WARNING:absl:Finished tracing + transforming _extract_sparse_vals for jit in 1.9684085845947266 sec\n",
            "WARNING:absl:Compiling _extract_sparse_vals (140345736409840) for 94 args.\n",
            "WARNING:absl:Finished XLA compilation of _extract_sparse_vals in 4.491841554641724 sec\n",
            "INFO:lumos.optimal_control.nlp:model_algebra.jacobian: 7.413820\n",
            "WARNING:absl:Finished tracing + transforming _extract_sparse_vals for jit in 3.7141165733337402 sec\n",
            "WARNING:absl:Compiling _extract_sparse_vals (140345735309648) for 95 args.\n",
            "WARNING:absl:Finished XLA compilation of _extract_sparse_vals in 8.575231313705444 sec\n",
            "INFO:lumos.optimal_control.nlp:model_algebra.hessian: 14.216124\n",
            "INFO:lumos.optimal_control.nlp:continuity.constraints: 0.005842\n",
            "INFO:lumos.optimal_control.nlp:continuity.jacobian: 0.009149\n",
            "INFO:lumos.optimal_control.nlp:continuity.hessian: 0.000127\n",
            "INFO:lumos.optimal_control.nlp:cyclic.constraints: 0.000483\n",
            "INFO:lumos.optimal_control.nlp:cyclic.jacobian: 0.000021\n",
            "INFO:lumos.optimal_control.nlp:cyclic.hessian: 0.000013\n",
            "INFO:lumos.optimal_control.scaled_mesh_ocp:Triggering jax JIT completed\n",
            "INFO:lumos.optimal_control.scaled_mesh_ocp:Time NLP execution\n",
            "INFO:lumos.optimal_control.nlp:time.objective: 0.000010\n",
            "INFO:lumos.optimal_control.nlp:time.gradient: 0.000362\n",
            "INFO:lumos.optimal_control.nlp:time.hessian: 0.000002\n",
            "INFO:lumos.optimal_control.nlp:inputs_penalty.objective: 0.000774\n",
            "INFO:lumos.optimal_control.nlp:inputs_penalty.gradient: 0.002009\n",
            "INFO:lumos.optimal_control.nlp:inputs_penalty.hessian: 0.000377\n",
            "INFO:lumos.optimal_control.nlp:model_algebra.constraints: 0.009059\n",
            "INFO:lumos.optimal_control.nlp:model_algebra.jacobian: 0.038848\n",
            "INFO:lumos.optimal_control.nlp:model_algebra.hessian: 0.058469\n",
            "INFO:lumos.optimal_control.nlp:continuity.constraints: 0.003274\n",
            "INFO:lumos.optimal_control.nlp:continuity.jacobian: 0.005736\n",
            "INFO:lumos.optimal_control.nlp:continuity.hessian: 0.000097\n",
            "INFO:lumos.optimal_control.nlp:cyclic.constraints: 0.000306\n",
            "INFO:lumos.optimal_control.nlp:cyclic.jacobian: 0.000009\n",
            "INFO:lumos.optimal_control.nlp:cyclic.hessian: 0.000003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'Algorithm terminated successfully at a locally optimal point, satisfying the convergence tolerances (can be specified by options).'\n",
            "finished in 129 iterations\n",
            "Maneuver time 114.964 sec\n"
          ]
        }
      ],
      "source": [
        "import logging\n",
        "import sys\n",
        "\n",
        "use_gpu_with_jax = True\n",
        "is_cyclic = True\n",
        "backend = \"jax\" # supports jax and casadi\n",
        "\n",
        "def main():\n",
        "    import jax\n",
        "    import os\n",
        "    import cyipopt\n",
        "    cyipopt.set_logging_level(logging.WARN)\n",
        "\n",
        "    from lumos.models.composition import ModelMaker\n",
        "    from lumos.models.simple_vehicle_on_track import SimpleVehicleOnTrack\n",
        "    from lumos.models.tires.utils import create_params_from_tir_file\n",
        "    from lumos.simulations.laptime_simulation import LaptimeSimulation\n",
        "\n",
        "    TRACK_DIR = \"data/tracks\"\n",
        "\n",
        "    \n",
        "    # Usually GPUs are designed to operate with float32 or even float16, and are\n",
        "    # much slower with doubles (float64). Here we stick with float64 to ensure\n",
        "    # we have the same results as 64bit as with casadi backend.\n",
        "    if use_gpu_with_jax:\n",
        "        jax.config.update('jax_platform_name', 'gpu')\n",
        "        os.environ['JAX_PLATFORM_NAME'] = 'GPU'\n",
        "        jax.config.update(\"jax_enable_x64\", True)\n",
        "    else:\n",
        "        # somehow jax doesn't see the cpu device on colab?!\n",
        "        jax.config.update('jax_platform_name', 'cpu')\n",
        "        os.environ['JAX_PLATFORM_NAME'] = 'CPU'\n",
        "        jax.config.update(\"jax_enable_x64\", True)\n",
        "\n",
        "\n",
        "    track = \"Catalunya\"\n",
        "    track_file = os.path.join(TRACK_DIR, track + \".csv\")\n",
        "\n",
        "    model_config = SimpleVehicleOnTrack.get_recursive_default_model_config()\n",
        "\n",
        "    # EXAMPLE: change tire model\n",
        "    # model_config.replace_subtree(\"vehicle.tire\", ModelMaker.make_config(\"PerantoniTire\"))\n",
        "\n",
        "    # EXMAPLE: change an aero model\n",
        "    # model_config.replace_subtree(\"vehicle.aero\", ModelMaker.make_config(\"MLPAero\"))\n",
        "\n",
        "    model = SimpleVehicleOnTrack(model_config=model_config)\n",
        "    params = model.get_recursive_default_params()\n",
        "\n",
        "    # Example of changing model parameters\n",
        "    # TODO: an issue here is that we need to instantiate the model first to get params\n",
        "    # but that's unavoidable because without the model, we don't even know the tree\n",
        "    # structure of all the submodels, let alone the default parameters.\n",
        "    # params.set_param(\"vehicle.vehicle_mass\", 1700)\n",
        "\n",
        "    # Example: change tire parameters\n",
        "    sharpened_params = create_params_from_tir_file(\"data/tires/sharpened.tir\")\n",
        "    # FIXME: here we're using private methods. We should probably add a method to change\n",
        "    # the parameters of an entire node in the ParameterTree\n",
        "    tire_params = params._get_subtree(\"vehicle.tire\")\n",
        "    tire_params._data = sharpened_params\n",
        "    params.replace_subtree(\"vehicle.tire\", tire_params)\n",
        "\n",
        "    final_outputs = {}\n",
        "    final_states = {}\n",
        "    ocp = LaptimeSimulation(\n",
        "        model_params=params,\n",
        "        model_config=model_config,\n",
        "        sim_config=LaptimeSimulation.get_sim_config(\n",
        "            num_intervals=2500,\n",
        "            hessian_approximation=\"exact\",\n",
        "            is_cyclic=is_cyclic,\n",
        "            is_condensed=False,\n",
        "            backend=backend,\n",
        "            track=track_file,\n",
        "            transcription=\"LGR\",\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    x0 = ocp.get_init_guess()\n",
        "\n",
        "\n",
        "    print(\"starting the first solve!\")\n",
        "    solution, info = ocp.solve(\n",
        "        x0,\n",
        "        max_iter=200,\n",
        "        print_level=5,\n",
        "        print_timing_statistics=\"yes\",\n",
        "        print_info_string=\"yes\",\n",
        "        dual_inf_tol=1e-3,\n",
        "        constr_viol_tol=1e-3,\n",
        "    )\n",
        "    total_time = ocp.dec_var_operator.get_var(\n",
        "        solution, group=\"states\", name=\"time\", stage=-1\n",
        "    )\n",
        "    print(info[\"status_msg\"])\n",
        "    print(f\"finished in {info['num_iter']} iterations\")\n",
        "    print(f\"Maneuver time {total_time:.3f} sec\")\n",
        "\n",
        "    # # We can change the parameters and solve again\n",
        "    # ocp.modify_model_param(\"vehicle.vehicle_mass\", 2100.0)\n",
        "    # print(\"starting the second solve!\")\n",
        "    # solution, info = ocp.solve(\n",
        "    #     solution,\n",
        "    #     max_iter=200,\n",
        "    #     print_level=5,\n",
        "    #     print_timing_statistics=\"yes\",\n",
        "    #     print_info_string=\"yes\",\n",
        "    #     derivative_test=\"none\",\n",
        "    #     dual_inf_tol=1e-3,\n",
        "    #     constr_viol_tol=1e-3,\n",
        "    # )\n",
        "    # total_time = ocp.dec_var_operator.get_var(\n",
        "    #     solution, group=\"states\", name=\"time\", stage=-1\n",
        "    # )\n",
        "    # print(f\"Maneuver time {total_time:.3f} sec\")\n",
        "\n",
        "# timing (note: this could be rather unstable due to the VM and resources available)\n",
        "# with 2500 intervals, per model algebra NLP call (con + jac + hess)\n",
        "# casadi:            : 1.35sec\n",
        "# JAX CPU            : 3.25sec (and 34.8sec for 25000 intervals, linear scaling)\n",
        "# JAX GPU K80 (64bit): 0.12sec (and 0.89sec for 25000 intervals, still sublinear scaling)\n",
        "\n",
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.DEBUG)\n",
        "main()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualiza results\n",
        "TODO: add some nice plots/animations"
      ],
      "metadata": {
        "id": "4Bj5bEo3gPWw"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Laptime simulation",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}